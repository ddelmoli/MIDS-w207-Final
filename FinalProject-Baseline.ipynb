{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GMM\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_ids, submission_data = [], []\n",
    "test_data, test_labels = [], []\n",
    "train_data, train_labels = [], []\n",
    "mini_train_data, mini_train_labels = [], []\n",
    "full_train_labels, full_train_data = [], []\n",
    "target_names, target_labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'irish', u'mexican', u'chinese', u'filipino', u'vietnamese', u'moroccan', u'brazilian', u'japanese', u'british', u'greek', u'indian', u'jamaican', u'french', u'spanish', u'russian', u'cajun_creole', u'thai', u'southern_us', u'korean', u'italian']\n",
      "(19887L,)\n"
     ]
    }
   ],
   "source": [
    "def parse_all_data(per_recipe_function=None):\n",
    "    global submission_ids, submission_data, test_data, test_labels, train_data, train_labels\n",
    "    global mini_train_data, mini_train_labels, full_train_labels, full_train_data, target_names, target_labels\n",
    "    def parse_data(key_name, raw_data):\n",
    "        keys, data = [], []\n",
    "        for recipe in raw_data:\n",
    "            keys.append(recipe[key_name])\n",
    "            #ingredient_list = \" \".join([x.replace(\" \",\"_\") for x in recipe[\"ingredients\"]])\n",
    "            ingredient_list = \" \".join([x for x in recipe[\"ingredients\"]])\n",
    "            ingredient_list = re.sub(r'[^A-Za-z\\s_]', '', ingredient_list)\n",
    "            #ingredient_list = re.sub(r'_+oz_', '', ingredient_list)\n",
    "            #ingredient_list = re.sub(r' _+', '', ingredient_list)\n",
    "            # This adds the word *count* to the list of ingredients equal to the number of ingredients\n",
    "            # this results in a vectorization that includes a last feature that has a count\n",
    "            # equal to the number of ingredients.\n",
    "            ingredient_list += (\" *count*\" * len(ingredient_list.split(\" \")))  \n",
    "\n",
    "            if per_recipe_function is not None:\n",
    "                ingredient_list = per_recipe_function(ingredient_list)\n",
    "\n",
    "            data.append(ingredient_list)\n",
    "        return keys, data\n",
    "\n",
    "    with open('train.json') as json_train_data:\n",
    "        train_raw = json.load(json_train_data)\n",
    "\n",
    "    with open('test.json') as json_test_data:\n",
    "        test_raw = json.load(json_test_data)\n",
    "\n",
    "    full_train_labels, full_train_data = parse_data(\"cuisine\", train_raw)\n",
    "\n",
    "    target_names = list(set(full_train_labels))\n",
    "    full_train_labels = np.array(full_train_labels)\n",
    "\n",
    "    submission_ids, submission_data = parse_data(\"id\", test_raw)\n",
    "\n",
    "    num_test = len(full_train_labels)\n",
    "    test_data, test_labels = full_train_data[num_test/2:], full_train_labels[num_test/2:]\n",
    "    train_data, train_labels = full_train_data[:num_test/2], full_train_labels[:num_test/2]\n",
    "\n",
    "    mini_train_data = train_data[:7000]\n",
    "    mini_train_labels = train_labels[:7000]\n",
    "    \n",
    "parse_all_data()\n",
    "\n",
    "print target_names\n",
    "print train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a balanced training set that has an equal number of recipes per cuisine so no one cuisine dominates our training\n",
    "ftd = np.array(full_train_data)\n",
    "ftl = np.array(full_train_labels)\n",
    "\n",
    "balanced_train_data = np.array([])\n",
    "balanced_train_labels = np.array([])\n",
    "\n",
    "recipes_per_cuisine = 300\n",
    "for cuisine in target_names:\n",
    "    balanced_train_data = np.append(balanced_train_data,ftd[ftl==cuisine][:recipes_per_cuisine])\n",
    "    balanced_train_labels = np.append(balanced_train_labels,[cuisine for i in range(recipes_per_cuisine)])\n",
    "    \n",
    "# Initial results using \"balanced\" data are not encouraging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'aai', u'abalone', u'abbamele', u'acai', u'accent', u'achiote', u'ackee', u'acorn', u'active', u'added']\n"
     ]
    }
   ],
   "source": [
    "this_train_data = mini_train_data\n",
    "this_train_labels = mini_train_labels\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "print sorted(features)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726428571429\n"
     ]
    }
   ],
   "source": [
    "this_train_data = mini_train_data\n",
    "this_train_labels = mini_train_labels\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "\n",
    "c = pow(2.0,np.arange(6)-6)\n",
    "parameters = {'C': c}\n",
    "lr = LogisticRegression()\n",
    "lr_clf = GridSearchCV(lr,parameters,scoring='accuracy')\n",
    "lr_clf.fit(train_docterm, this_train_labels)\n",
    "print lr_clf.best_score_\n",
    "\n",
    "#alpha = pow(2.0,np.arange(24)-12)\n",
    "#parameters = {'alpha': alpha}\n",
    "#mnb = MultinomialNB()\n",
    "#mnb_clf = GridSearchCV(mnb,parameters,scoring='accuracy')\n",
    "#mnb_clf.fit(train_docterm, train_labels)\n",
    "#print mnb_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 C:    0.01562  Vocabulary Size:    57  L2 Accuracy: 0.59571  L2 C:    0.50000\n",
      "L1 C:    0.03125  Vocabulary Size:   108  L2 Accuracy: 0.65314  L2 C:    0.50000\n",
      "L1 C:    0.06250  Vocabulary Size:   175  L2 Accuracy: 0.68786  L2 C:    0.50000\n",
      "L1 C:    0.12500  Vocabulary Size:   282  L2 Accuracy: 0.71114  L2 C:    0.50000\n",
      "L1 C:    0.25000  Vocabulary Size:   426  L2 Accuracy: 0.72171  L2 C:    0.50000\n",
      "L1 C:    0.50000  Vocabulary Size:   616  L2 Accuracy: 0.72686  L2 C:    0.50000\n",
      "L1 C:    1.00000  Vocabulary Size:   883  L2 Accuracy: 0.72957  L2 C:    0.50000\n",
      "L1 C:    2.00000  Vocabulary Size:  1310  L2 Accuracy: 0.72700  L2 C:    0.50000\n",
      "L1 C:    4.00000  Vocabulary Size:  1495  L2 Accuracy: 0.72700  L2 C:    0.50000\n",
      "L1 C:    8.00000  Vocabulary Size:  1592  L2 Accuracy: 0.72643  L2 C:    0.50000\n",
      "L1 C:   16.00000  Vocabulary Size:  1653  L2 Accuracy: 0.72671  L2 C:    0.50000\n",
      "L1 C:   32.00000  Vocabulary Size:  1738  L2 Accuracy: 0.72629  L2 C:    0.50000\n"
     ]
    }
   ],
   "source": [
    "this_train_data = mini_train_data\n",
    "this_train_labels = mini_train_labels\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "total_vocab = vectorizer.vocabulary_\n",
    "total_vocab_byidx = dict((v,k) for k,v in vectorizer.vocabulary_.iteritems())\n",
    "\n",
    "vocab_sizes = []\n",
    "accuracies = []\n",
    "\n",
    "for c_l1 in pow(2.0,np.arange(12)-6):\n",
    "\n",
    "    # Train LogisticRegression with L1 penalty and specific C\n",
    "    lr_l1 = LogisticRegression(penalty='l1', tol=.01, C=c_l1)\n",
    "    lr_l1.fit(train_docterm, this_train_labels)\n",
    "\n",
    "    # Create a pruned vocabulary based on non-zero features from LogisticRegression with L1 penalty\n",
    "    pruned_vocab = set()\n",
    "    for f in lr_l1.coef_:\n",
    "        pruned_vocab.update([total_vocab_byidx[i] for i in np.flatnonzero(f)])\n",
    "\n",
    "    # Create a pruning vectorizer\n",
    "    pruning_vectorizer = CountVectorizer(vocabulary=pruned_vocab)\n",
    "    pruned_train_docterm = pruning_vectorizer.fit_transform(this_train_data)\n",
    "\n",
    "    # Train LogisticRegression with L2 penalty and pruned vocabulary\n",
    "    c = pow(2.0,np.arange(12)-12)\n",
    "    parameters = {'penalty' : ['l2'], 'C': c}\n",
    "    lr = LogisticRegression()\n",
    "    lr_clf = GridSearchCV(lr,parameters,scoring='accuracy')\n",
    "    lr_clf.fit(pruned_train_docterm, this_train_labels)\n",
    "    c_l2 = lr_clf.best_params_['C']\n",
    "\n",
    "    print \"L1 C: %10.5f  Vocabulary Size: %5d  L2 Accuracy: %.5f  L2 C: %10.5f\" % (c_l1, len(pruned_vocab), lr_clf.best_score_, c_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission_csv(classifier=None, data=None, predictions=None):\n",
    "    with open('submission.csv', 'wb') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['id', 'cuisine'])\n",
    "        if predictions is None:\n",
    "            predictions = classifier.predict(data)\n",
    "        for i in range(len(submission_data)):\n",
    "            csvwriter.writerow([submission_ids[i], predictions[i].strip()])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in 0.78138 accuracy on Kaggle for 710th place with the full training set.\n"
     ]
    }
   ],
   "source": [
    "parse_all_data()\n",
    "\n",
    "this_train_data = full_train_data\n",
    "this_train_labels = full_train_labels\n",
    "\n",
    "def create_pruned_vectorizer(data, labels):\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_docterm = vectorizer.fit_transform(data)\n",
    "    total_vocab = vectorizer.vocabulary_\n",
    "    total_vocab_byidx = dict((v,k) for k,v in vectorizer.vocabulary_.iteritems())\n",
    "\n",
    "    lr_l1 = LogisticRegression(penalty='l1', tol=.01, C=1.0)\n",
    "    lr_l1.fit(train_docterm, labels)\n",
    "\n",
    "    pruned_vocab = set()\n",
    "    for f in lr_l1.coef_:\n",
    "        pruned_vocab.update([total_vocab_byidx[i] for i in np.flatnonzero(f)])\n",
    "\n",
    "    pruning_vectorizer = CountVectorizer(vocabulary=pruned_vocab)\n",
    "    \n",
    "    return pruning_vectorizer\n",
    "\n",
    "pruning_vectorizer = create_pruned_vectorizer(this_train_data, this_train_labels)\n",
    "pruned_train_docterm = pruning_vectorizer.fit_transform(this_train_data)\n",
    "pruned_test_docterm = pruning_vectorizer.transform(submission_data)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=0.5)\n",
    "lr.fit(pruned_train_docterm, this_train_labels)\n",
    "\n",
    "create_submission_csv(lr, pruned_test_docterm)\n",
    "\n",
    "print \"Results in 0.78138 accuracy on Kaggle for 710th place with the full training set.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - S1\n",
    "\n",
    "Idea: In this experiment we add simple ingredients to the text stream for a recipe and an indicator if a recipe contains meat, seafood or animal product. \n",
    "\n",
    "Outcome: Some minor increase in accuracy above the baseline was achieved in our Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_ingredients = [\"chicken\", \"tomatoes\", \"rice\", \"garlic\", \"milk\", \"water\", \"cheese\", \"peanuts\",\n",
    "                      \"beef\", \"mushrooms\", \"pork\" ]  \n",
    "seafood_ingredients = [\"fish\", \"tuna\", \"salmon\", \"crab\", \"shrimp\", \"prawn\", \"calamari\", \"anchovy\"]\n",
    "meat_ingredients = [\"beef\", \"steak\", \"chicken\", \"pork\", \"bacon\", \"ham\",  \"turkey\", \"meat\"]\n",
    "pasta_ingredients = [\"tortellini\",\"fettucine\",\"linguine\",\"spaghetti\",\"rotini\",\"spaghettini\",\"diatlini\",\"penne\",\n",
    "                     \"macaroni\",\"ziti\",\"lasagna\",\"capellini\",\"fusilli\",\"pappardelle\",\"tagliatelle\",\"canneloni\",\n",
    "                     \"manicotti\",\"rigatoni\"]\n",
    "animal_product_ingredients = [\"egg\", \"butter\", \"milk\", \"cheese\"]\n",
    "\n",
    "def add_contains_feature(ingredients, contains_feature_name, recipe):\n",
    "    for ing in ingredients:\n",
    "        if ing in recipe:\n",
    "            recipe += \" \" + contains_feature_name\n",
    "    return recipe\n",
    "\n",
    "def add_simple_ingredients_features(ingredient_list):\n",
    "    for ing in simple_ingredients:\n",
    "        if ing in ingredient_list:\n",
    "            ingredient_list += \" \" + ing + \" \"\n",
    "    return ingredient_list\n",
    "\n",
    "def add_ingredient_group_features(ingredient_list):\n",
    "    ingredient_list = add_contains_feature(seafood_ingredients, \"contains_seafood\", ingredient_list)\n",
    "    ingredient_list = add_contains_feature(meat_ingredients, \"contains_meat\", ingredient_list)\n",
    "    #ingredient_list = add_contains_feature(pasta_ingredients, \"contains_italian_pasta\", ingredient_list)\n",
    "    # This next one decreases our accuracy a little.\n",
    "    # ingredient_list = add_contains_feature(animal_product_ingredients, \"contains_animal_product\", ingredient_list)\n",
    "    return ingredient_list\n",
    "\n",
    "def add_experimentS1_features(ingredient_list):\n",
    "    ingredient_list = add_simple_ingredients_features(ingredient_list)\n",
    "    ingredient_list = add_ingredient_group_features(ingredient_list)\n",
    "    return ingredient_list\n",
    "    \n",
    "parse_all_data(add_experimentS1_features)\n",
    "this_train_data = full_train_data\n",
    "this_train_labels = full_train_labels\n",
    "\n",
    "lr = LogisticRegression(C=1.0)\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "# achieved exact same accuracy with the pruned version of our vocabulary\n",
    "#vectorizer = create_pruned_vectorizer(this_train_data, this_train_labels)\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "test_docterm = vectorizer.transform(full_train_data)\n",
    "\n",
    "lr.fit(train_docterm, this_train_labels)\n",
    "predictions = lr.predict(test_docterm)\n",
    "print np.mean(full_train_labels == predictions)\n",
    "\n",
    "create_submission_csv(lr, vectorizer.transform(submission_data))\n",
    "\n",
    "print \"Results in 0.79083 accuracy on Kaggle for 400th place when using full training set.\"\n",
    "#0.98446 - highest seen on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - S2\n",
    "\n",
    "Idea: Use PCA to reduce features then train on reduced feature set.\n",
    "\n",
    "Outcome: Because we vectorize the the ingredients list the data is very sparse. PCA does not run on a sparse matrix. Converting the sparse matrix to a dense array causes python to crash. Probably we run out of memory. Perhaps this process could be tried on a machine with more memory or perhaps PCA isn't appropriate for sparse features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parse_all_data()\n",
    "this_train_data = train_data\n",
    "this_train_labels = train_labels\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "test_docterm = vectorizer.transform(test_data)\n",
    "\n",
    "# THIS WILL TAKE FOREVER TO RUN. I wouldn't try it.\n",
    "#pca = PCA(n_components=20).fit(train_docterm.toarray())\n",
    "#for k in range(1,51):\n",
    "#    explained_variance = sum(pca.explained_variance_ratio_[0:k])\n",
    "#    print \"Variance Explained by first %s components: %s\" % (k, explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - S4\n",
    "\n",
    "Idea: For many recipes the most \"important\" ingredient is listed first. We'll try to give extra weight to the first word or first couple of words.\n",
    "\n",
    "Outcome: Submission accuracy is slightly worse than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765877206215\n",
      "Results in 0.76398 accuracy on Kaggle for 851th place when using full training set.\n"
     ]
    }
   ],
   "source": [
    "def duplicate_first_ingredient(ingredients_list):\n",
    "    first = ingredients_list.split(\" \")[0]\n",
    "    return ingredients_list + \" \" + first\n",
    "    \n",
    "parse_all_data(duplicate_first_ingredient)\n",
    "this_train_data = train_data\n",
    "this_train_labels = train_labels\n",
    "\n",
    "lr = LogisticRegression(C=1.0)\n",
    "vectorizer = create_pruned_vectorizer(this_train_data, this_train_labels)\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "test_docterm = vectorizer.transform(test_data)\n",
    "\n",
    "lr.fit(train_docterm, this_train_labels)\n",
    "predictions = lr.predict(test_docterm)\n",
    "print np.mean(test_labels == predictions)\n",
    "#create_submission_csv(lr, vectorizer.transform(submission_data))\n",
    "\n",
    "print \"Results in 0.76398 accuracy on Kaggle for 851th place when using full training set.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - S5\n",
    "\n",
    "Idea: Play with RandomForests and AdaBoost.\n",
    "\n",
    "Outcome: Neither produced stellar accuracy, but RandomForests did perform substantially better than a single decision tree so we now use it as our third in the majority vote predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 40}\n",
      "0.732488560366\n",
      "{'n_estimators': 40}\n",
      "0.535123447478\n"
     ]
    }
   ],
   "source": [
    "parse_all_data()\n",
    "this_train_data = train_data\n",
    "this_train_labels = train_labels\n",
    "\n",
    "vectorizer = create_pruned_vectorizer(this_train_data, this_train_labels)\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "test_docterm = vectorizer.transform(test_data)\n",
    "\n",
    "n_estimators = 35\n",
    "params = {\"n_estimators\" : [30,31,35,40]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), params, scoring='f1_micro')\n",
    "grid_search.fit(train_docterm, this_train_labels)   \n",
    "print grid_search.best_params_\n",
    "n_estimators = grid_search.best_params_[\"n_estimators\"]\n",
    "rfc = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "rfc.fit(train_docterm, this_train_labels)\n",
    "predictions = rfc.predict(test_docterm)\n",
    "print np.mean(test_labels == predictions)\n",
    "\n",
    "n_estimators = 50\n",
    "params = {\"n_estimators\" : [40,50,60]}\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(), params, scoring='f1_micro')\n",
    "grid_search.fit(train_docterm, this_train_labels)   \n",
    "print grid_search.best_params_\n",
    "n_estimators = grid_search.best_params_[\"n_estimators\"]\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=n_estimators)\n",
    "abc.fit(train_docterm, this_train_labels)\n",
    "predictions = abc.predict(test_docterm)\n",
    "print np.mean(test_labels == predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - S3\n",
    "\n",
    "Idea: Run multipe classifiers and see if a majority rules can produce better results.\n",
    "\n",
    "Outcome: KNearest neighbor is pretty bad and slow. Decision Tree results are not great, better than a flip of a coin and much quicker than KNearest neighbors. The end result is with Logistic Regression, Multinomial Bayes and a very poor performing decision tree is worse performance than the baseline. After doing testing on RandomForest it performed better than a standard decision tree so trying the majoirty rules with it as the third. Using RandomForest as the third upped our Kaggle accuracy by about 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845778649369\n",
      "0.744305325087\n",
      "0.999597727158\n",
      "Majority rules:  0.908583496757\n",
      "Results in 0.77936 accuracy on Kaggle for 727th place when using full training set.\n"
     ]
    }
   ],
   "source": [
    "def majority_predictions(one, two, three):\n",
    "    new_predictions = []\n",
    "    for i, value in enumerate(one):\n",
    "        if value == two[i]:\n",
    "            new_predictions.append(value)\n",
    "        else:\n",
    "            new_predictions.append(three[i])\n",
    "    return new_predictions\n",
    "\n",
    "    \n",
    "parse_all_data()\n",
    "this_train_data = full_train_data\n",
    "this_train_labels = full_train_labels\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "test_docterm = vectorizer.transform(test_data)\n",
    "\n",
    "#lr = LogisticRegression(C=1.0)\n",
    "lr.fit(train_docterm, this_train_labels)\n",
    "lr_predictions = lr.predict(test_docterm)\n",
    "print np.mean(test_labels == lr_predictions)\n",
    "\n",
    "\n",
    "# find optimal alpha for multinomial naive bayes\n",
    "alphas = {\"alpha\" : [.00001, .0001, .001, .01, .1, 1, 10, 100, 1000]}\n",
    "grid_search = GridSearchCV(MultinomialNB(), alphas, scoring='f1_micro')\n",
    "grid_search.fit(train_docterm, this_train_labels)   \n",
    "\n",
    "# Calculate f1 score for best alpha\n",
    "mnb = MultinomialNB(alpha=grid_search.best_params_['alpha'])\n",
    "mnb.fit(train_docterm, this_train_labels)\n",
    "mnb_predictions = mnb.predict(test_docterm)\n",
    "print np.mean(test_labels == mnb_predictions)\n",
    "\n",
    "#k_values = {\"n_neighbors\" : range(1, 20)}\n",
    "#grid_search = GridSearchCV(KNeighborsClassifier(), k_values, scoring='f1_micro')\n",
    "#grid_search.fit(train_docterm, this_train_labels)\n",
    "#print \"best n\", grid_search.best_params_['n_neighbors']\n",
    "#best_n = grid_search.best_params_['n_neighbors']\n",
    "#best_n = 16 \n",
    "\n",
    "# Calculate f1 score for best k\n",
    "# Two slow and poor accuracy\n",
    "#knc = KNeighborsClassifier(n_neighbors=best_n)\n",
    "#knc.fit(train_docterm, this_train_labels)\n",
    "#predictions = knc.predict(test_docterm)\n",
    "#print np.mean(test_labels == predictions)\n",
    "\n",
    "\n",
    "#params = {\"min_samples_split\" : [2,3,4,5,6,7], \"min_samples_leaf\" : [1,2,3,4,5]}\n",
    "#grid_search = GridSearchCV(DecisionTreeClassifier(), params, scoring='f1_micro')\n",
    "#grid_search.fit(train_docterm, this_train_labels)   \n",
    "#print grid_search.best_params_\n",
    "\n",
    "#dtc = DecisionTreeClassifier(min_samples_split=4, min_samples_leaf=1)\n",
    "#dtc.fit(train_docterm, this_train_labels)\n",
    "#dtc_predictions = dtc.predict(test_docterm)\n",
    "#print np.mean(test_labels == dtc_predictions)\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=35)\n",
    "rfc.fit(train_docterm, this_train_labels)\n",
    "rfc_predictions = rfc.predict(test_docterm)\n",
    "print np.mean(test_labels == rfc_predictions)\n",
    "\n",
    "predictions = majority_predictions(lr_predictions, mnb_predictions, rfc_predictions)\n",
    "print \"Majority rules: \", np.mean(test_labels == predictions)\n",
    "\n",
    "submission_docterm = vectorizer.transform(submission_data)\n",
    "lr_predictions = lr.predict(submission_docterm)\n",
    "mnb_predictions = mnb.predict(submission_docterm)\n",
    "#dtc_predictions = dtc.predict(submission_docterm)\n",
    "rfc_predictions = rfc.predict(submission_docterm)\n",
    "predictions = majority_predictions(lr_predictions, mnb_predictions, rfc_predictions)\n",
    "\n",
    "create_submission_csv(predictions=predictions)\n",
    "\n",
    "print \"Results in 0.77936 accuracy on Kaggle for 727th place when using full training set.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis \n",
    "\n",
    "Try to determine what is being incorrectly guessed. Experiment S1 produced the best results and should therefore be used for error analysis. \n",
    "\n",
    "Results: French and Italian seem to be the hardest to tell apart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.772464423996\n",
      "0 is irish\n",
      "1 is mexican\n",
      "2 is chinese\n",
      "3 is filipino\n",
      "4 is vietnamese\n",
      "5 is moroccan\n",
      "6 is brazilian\n",
      "7 is japanese\n",
      "8 is british\n",
      "9 is greek\n",
      "10 is indian\n",
      "11 is jamaican\n",
      "12 is french\n",
      "13 is spanish\n",
      "14 is russian\n",
      "15 is cajun_creole\n",
      "16 is thai\n",
      "17 is southern_us\n",
      "18 is korean\n",
      "19 is italian\n",
      "\n",
      "\n",
      "irish most often confused with southern_us 72\n",
      "mexican most often confused with southern_us 77\n",
      "chinese most often confused with japanese 35\n",
      "filipino most often confused with chinese 40\n",
      "vietnamese most often confused with thai 80\n",
      "moroccan most often confused with italian 26\n",
      "brazilian most often confused with mexican 31\n",
      "japanese most often confused with chinese 72\n",
      "british most often confused with southern_us 80\n",
      "greek most often confused with italian 109\n",
      "indian most often confused with mexican 27\n",
      "jamaican most often confused with southern_us 29\n",
      "french most often confused with italian 295\n",
      "spanish most often confused with italian 100\n",
      "russian most often confused with french 35\n",
      "cajun_creole most often confused with southern_us 132\n",
      "thai most often confused with vietnamese 63\n",
      "southern_us most often confused with italian 100\n",
      "korean most often confused with chinese 45\n",
      "italian most often confused with french 158\n",
      "\n",
      "\n",
      "Incorrect Prediction. Expected: mexican seen southern_us\n",
      "Ingredients: garlic powder cayenne pepper eggs diced tomatoes cornmeal chili powder boneless pork loin milk salt corn kernel whole *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* tomatoes  garlic  milk  pork  contains_meat contains_meat \n",
      "\n",
      "Incorrect Prediction. Expected: chinese seen thai\n",
      "Ingredients: salad greens sesame seeds green onions boiling water green tea bags honey asian pear garlic cloves cherry tomatoes green tea salt fish sauce olive oil extra firm tofu fresh lime juice *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* tomatoes  garlic  water  contains_seafood \n",
      "\n",
      "Incorrect Prediction. Expected: indian seen thai\n",
      "Ingredients: curry powder cooking spray orange juice dijon mustard crushed red pepper large shrimp reduced fat creamy peanut butter vegetable oil chile sauce orange marmalade salt *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* contains_seafood \n",
      "\n",
      "Incorrect Prediction. Expected: french seen italian\n",
      "Ingredients: dijon mustard extravirgin olive oil flat leaf parsley water green onions fresh lemon juice capers zucchini garlic cloves fresh basil leaves olive oil Italian parsley leaves green beans *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* garlic  water  \n",
      "\n",
      "Incorrect Prediction. Expected: italian seen greek\n",
      "Ingredients: green chile large eggs garlic cloves pepper diced tomatoes garlic herb feta baby spinach olive oil salt *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* tomatoes  garlic  \n",
      "\n",
      "Incorrect Prediction. Expected: jamaican seen southern_us\n",
      "Ingredients: plain flour sugar bananas baking powder eggs caster sugar unsalted butter vanilla extract bicarbonate of soda lime juice dry coconut salt lime zest toasted pecans milk dark rum cream cheese *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* milk  cheese  \n",
      "\n",
      "Incorrect Prediction. Expected: french seen italian\n",
      "Ingredients: sweet cherries allpurpose flour sugar large eggs kirsch vanilla beans whole milk sour cream mascarpone heavy whipping cream *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* milk  \n",
      "\n",
      "Incorrect Prediction. Expected: vietnamese seen chinese\n",
      "Ingredients: bean threads Sriracha vegetable stock cinnamon sticks lime green onions ginger onions clove coriander seeds rice noodles star anise frozen shelled edamame kecap manis cilantro bok choy *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* rice  \n",
      "\n",
      "Incorrect Prediction. Expected: irish seen italian\n",
      "Ingredients: salt freshly ground pepper savoy cabbage butter *count* *count* *count* *count* *count* *count* *count* \n",
      "\n",
      "Incorrect Prediction. Expected: spanish seen southern_us\n",
      "Ingredients: baking powder powdered sugar vanilla extract sugar allpurpose flour eggs butter *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* *count* \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parse_all_data(add_experimentS1_features)\n",
    "this_train_data = train_data\n",
    "this_train_labels = train_labels\n",
    "\n",
    "\n",
    "def report_errors(predictions, test_data, test_labels, ingredients, number_of_errors_to_report=10):\n",
    "    print \"Overall Accuracy:\", np.mean(test_labels == predictions)\n",
    "    \n",
    "    for i, label in enumerate(target_names):\n",
    "        print i,\"is\",label\n",
    "        \n",
    "    print \"\\n\"\n",
    "    confusion =  confusion_matrix(test_labels, predictions, labels=target_names)\n",
    "    for i, row in enumerate(confusion):\n",
    "        max_so_far = None\n",
    "        for j, column in enumerate(row):\n",
    "            if i != j and (max_so_far is None or column > row[max_so_far]):\n",
    "                max_so_far = j\n",
    "                \n",
    "        print target_names[i], \"most often confused with\", target_names[max_so_far], row[max_so_far]\n",
    "    \n",
    "    print \"\\n\"\n",
    "    count = 0\n",
    "    for i, label in enumerate(predictions):\n",
    "        if count == number_of_errors_to_report: break\n",
    "        if label != test_labels[i]:\n",
    "            print \"Incorrect Prediction. Expected:\", test_labels[i], \"seen\", label\n",
    "            print \"Ingredients:\", ingredients[i], \"\\n\"\n",
    "            count += 1\n",
    "    \n",
    "    \n",
    "lr = LogisticRegression(C=1.0)\n",
    "vectorizer = CountVectorizer()\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "test_docterm = vectorizer.transform(test_data)\n",
    "\n",
    "lr.fit(train_docterm, this_train_labels)\n",
    "predictions = lr.predict(test_docterm)\n",
    "\n",
    "report_errors(predictions, test_docterm, test_labels, test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment S4 - Post Error Analysis\n",
    "\n",
    "Idea - There seem to be two distinct groups of errors: mistaking one asian cuisine with another and likewise for european/americas. We'll try to split the data into two groups. Then train additional models that use just the data from those two groups to instantiate classifiers. When a prediction is made with the base classifier (which considers all ethnicities) we'll see which group it falls into and then reclassify with the more specific classifier.\n",
    "\n",
    "Results: Minor improvements before changes to how we processed the ingredient lits were made. When we stopped considering ingredients as a single string this started hurting our Kaggle results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_predictions_of_subgroup(test_data, predictions, group_labels):\n",
    "    group_train_data = [this_train_data[index] for index, data in enumerate(this_train_labels) if data in group_labels]\n",
    "    group_train_labels = [this_train_labels[index] for index, data in enumerate(this_train_labels) if data in group_labels]    \n",
    "\n",
    "    lr = LogisticRegression(C=1.0)\n",
    "    vectorizer = CountVectorizer()\n",
    "    group_train_docterm = vectorizer.fit_transform(group_train_data)        \n",
    "\n",
    "    # take any prediction from europe descent and rerun it through our group specific classifier\n",
    "    group_test_data = [test_data[index] for index, data in enumerate(predictions) if data in group_labels]\n",
    "    group_test_docterm = vectorizer.transform(group_test_data)\n",
    "    lr.fit(group_train_docterm, group_train_labels)\n",
    "    group_predictions = lr.predict(group_test_docterm)\n",
    "\n",
    "    group_index = 0\n",
    "    for index, label in enumerate(predictions):\n",
    "        if label in group_labels:\n",
    "            predictions[index] = group_predictions[group_index]\n",
    "            group_index += 1  \n",
    "            \n",
    "    return predictions\n",
    "            \n",
    "\n",
    "\n",
    "parse_all_data(add_experimentS1_features)\n",
    "this_train_data = full_train_data\n",
    "this_train_labels = full_train_labels\n",
    "this_test_data = submission_data\n",
    "\n",
    "euro_labels = [\"french\", \"italian\", \"greek\", 'russian', \"moroccan\", \"spanish\", \"southern_us\", \"irish\", \n",
    "               'mexican', \"brazilian\", \"british\", \"cajun_creole\"]\n",
    "\n",
    "asian_labels = [\"filipino\", \"chinese\", \"vietnamese\", 'japanese', \"thai\", \"korean\"]\n",
    "\n",
    "# train the entire set as normal\n",
    "lr = LogisticRegression(C=1.0)\n",
    "vectorizer = CountVectorizer()\n",
    "train_docterm = vectorizer.fit_transform(this_train_data)\n",
    "test_docterm = vectorizer.transform(this_test_data)\n",
    "\n",
    "# predict overall results\n",
    "lr.fit(train_docterm, this_train_labels)\n",
    "predictions = lr.predict(test_docterm)\n",
    "        \n",
    "# update predictions based on subgroups    \n",
    "predictions =  update_predictions_of_subgroup(this_test_data, predictions, euro_labels)   \n",
    "predictions =  update_predictions_of_subgroup(this_test_data, predictions, asian_labels)   \n",
    "\n",
    "create_submission_csv(predictions=predictions)\n",
    "\n",
    "#report_errors(predictions, test_docterm, test_labels, test_data, 0)\n",
    "\n",
    "print \"Results in 0.78701 accuracy on Kaggle for 564th place when using full training set.\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
